{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff71f269",
   "metadata": {},
   "source": [
    "# Independent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9e6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import random\n",
    "import math\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Conv2DTranspose, Activation\n",
    "from keras.layers import concatenate, BatchNormalization, Dropout, Add, RepeatVector, Reshape\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "#from tensorflow.keras.optimizers import SGD , Adam\n",
    "from keras.optimizers import SGD , Adam\n",
    "# from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382dd3",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985c1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--decay', type=float, default=0.01)\n",
    "parser.add_argument('--batch', type=int, default=128)\n",
    "parser.add_argument('--epoch', type=int, default=1000)\n",
    "parser.add_argument('--drop_p', type=float, default=0.1)\n",
    "parser.add_argument('--reg', type=float, default=0.0)\n",
    "parser.add_argument('--test', action='store_true')\n",
    "\n",
    "parser.add_argument('--output_dir', type=str, default='./output/')\n",
    "parser.add_argument('--save_dir', type=str, default='./model_saved/')\n",
    "parser.add_argument('--model_name', type=str, default='no_named')\n",
    "\n",
    "parser.add_argument('--scale', type=str, default='min_max')\n",
    "parser.add_argument('--dataset_name', type=str, default='NYC')\n",
    "parser.add_argument('--thr', type=int, default=10)\n",
    "parser.add_argument('--alpha', type=float, default=0.05)\n",
    "parser.add_argument('--num_gpu', type=int, default=1)\n",
    "parser.add_argument('--coord', type=float, default=25.0)\n",
    "parser.add_argument('--coord_net', type=int, default=2)\n",
    "\n",
    "parser.add_argument('--temp', type=int, default=16)\n",
    "parser.add_argument('--nf', type=int, default=32)\n",
    "parser.add_argument('--enf', type=int, default=64)\n",
    "parser.add_argument('--patience', type=int, default=150)\n",
    "parser.add_argument('--es', type=str, default='min')\n",
    "\n",
    "args, extras = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df60659",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea7719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np_data(filename):\n",
    "    try:\n",
    "        data = np.load(filename)['arr_0']\n",
    "        print(\"[*] Success to load \", filename)\n",
    "        return data\n",
    "    except:\n",
    "        raise IOError(\"Fail to load data\", filename)\n",
    "\n",
    "def get_min_max(data, scale='min_max'):\n",
    "    if scale=='min_max':\n",
    "        return np.min(data), np.max(data)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def min_max(data, min_value, max_value):\n",
    "    result = data - min_value\n",
    "    scale = max_value - min_value\n",
    "    assert scale > 0\n",
    "    result = result/scale\n",
    "    return result\n",
    "\n",
    "def scaler(data, scale_type='log', inv=False, min_value=None, max_value=None):\n",
    "    if scale_type == 'log':\n",
    "        if not inv:\n",
    "            print(\"[*] \", np.shape(data), \":log scaled\")\n",
    "            return logscale(data)\n",
    "        else:\n",
    "            print(\"[*] \", np.shape(data), \": inverse log scaled\")\n",
    "            return inverse_logscale(data)\n",
    "    elif scale_type == 'min_max':\n",
    "        assert (min_value != None) and (max_value != None)\n",
    "        if not inv:\n",
    "            return min_max(data, min_value, max_value)\n",
    "        else:\n",
    "            return inverse_min_max(data, min_value, max_value)\n",
    "    else:\n",
    "        print(\"[!] invalid scale type: \", scale_type)\n",
    "        raise\n",
    "        \n",
    "def inverse_min_max(data, min_value, max_value):\n",
    "    scale = max_value - min_value\n",
    "    result = scale * data + min_value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ffb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(STAMP, LAG, STEP, train=True, valid=False):\n",
    "    \n",
    "#     args.model_name = f'SeoulFloatingPop_lag{LAG}_step{STEP}'\n",
    "\n",
    "    ### train set\n",
    "\n",
    "    x_train = load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "    min_x, max_x = get_min_max(x_train, 'min_max')\n",
    "\n",
    "    if train:    \n",
    "        y_train = load_np_data(f'./data/y_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_train = load_np_data(f'./data/temporal_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_train = temporal_train.reshape(temporal_train.shape[0],temporal_train.shape[2])\n",
    "        \n",
    "        # Min Max Scaling\n",
    "        x_train = scaler(x_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_train = scaler(y_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        \n",
    "        ### validation set\n",
    "        valid_ratio=0.2\n",
    "        num_train = int(len(x_train)*(1.0-valid_ratio))\n",
    "        x_train, x_valid = x_train[:num_train], x_train[num_train:]\n",
    "        temporal_train, temporal_valid = temporal_train[:num_train], temporal_train[num_train:]\n",
    "        y_train, y_valid = y_train[:num_train], y_train[num_train:]\n",
    "        \n",
    "        if valid:\n",
    "            \n",
    "            print(f'x_valid.shape = {x_valid.shape}')\n",
    "            print(f'y_valid.shape = {y_valid.shape}')\n",
    "            print(f'temporal_valid.shape = {temporal_valid.shape}')\n",
    "        \n",
    "            return x_valid, temporal_valid, y_valid\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('--- training dataset ---')\n",
    "            print(f'x_train.shape = {x_train.shape}')\n",
    "            print(f'y_train.shape = {y_train.shape}')\n",
    "            print(f'temporal_train.shape = {temporal_train.shape}')\n",
    "\n",
    "            return x_train, temporal_train, y_train\n",
    "    \n",
    "    else: ### test set\n",
    "\n",
    "        x_test = load_np_data(f'./data/x_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        y_test = load_np_data(f'./data/y_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_test = load_np_data(f'./data/temporal_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "\n",
    "        # Min Max Scaling\n",
    "        x_test = scaler(x_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_test = scaler(y_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "\n",
    "        print('--- test dataset ---')\n",
    "        print(f'x_test.shape = {x_test.shape}')\n",
    "        print(f'y_test.shape = {y_test.shape}')\n",
    "        print(f'temporal_test.shape = {temporal_test.shape}')\n",
    "\n",
    "        return x_test, temporal_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed9907",
   "metadata": {},
   "source": [
    "# TGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343db561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    rtn = np.sqrt(  np.average( np.square(y_pred-y_true) ) )\n",
    "    return  rtn\n",
    "\n",
    "def mape(y_true,y_pred):\n",
    "    rtn = np.mean(np.abs((y_true - y_pred) / (1.0+y_true)))\n",
    "    return rtn\n",
    "\n",
    "def mape_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.divide(np.abs(y_true-y_pred)[true_mask] , y_true[true_mask])\n",
    "\n",
    "    rtn = (np.average(tmp_abs))\n",
    "    return rtn\n",
    "\n",
    "def rmse_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.sqrt(np.average(np.square(y_pred-y_true)[true_mask]))\n",
    "    return tmp_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ce0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gn_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='SAME', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = AveragePooling2D(kernel_size, strides, padding)(input)\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "\n",
    "    net_sf = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "\n",
    "    net = Add()([net, net_sf])\n",
    "    net = concatenate([input, net])\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "    net = BatchNormalization()(net)\n",
    "\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net\n",
    "\n",
    "def deconv_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = Conv2DTranspose(num_c, kernel_size=kernel_size, strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "    net = BatchNormalization()(net)\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277b5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGNet(input_shape):\n",
    "    nf = args.nf\n",
    "    h,w = input_shape[:2]\n",
    "    start_input = Input(shape=input_shape)\n",
    "    temporal_input = Input(shape=(55,))\n",
    "    input_tensors = [start_input, temporal_input]\n",
    "\n",
    "\n",
    "    ### Temporal guided embedding\n",
    "    net_temp = Dense(args.temp, activation='relu')(temporal_input)\n",
    "    # self.net_temp = Dense(args.temp, activation='relu')(net_temp)\n",
    "    net_temp = RepeatVector(h*w)(net_temp)\n",
    "    net_temp = Reshape((h,w,args.temp))(net_temp)\n",
    "\n",
    "    ### U-net layers\n",
    "    net1 = concatenate([start_input, net_temp], axis=-1)\n",
    "    net1 = gn_block(net1, nf, dropout=args.drop_p,regularizer=args.reg)\n",
    "    net11 = AveragePooling2D(pool_size=(2,2))(net1)\n",
    "    net2 = gn_block(net11, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net3 = gn_block(net2, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net33 = concatenate([net2, net3])\n",
    "    net4 = gn_block(net33, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net4 = concatenate([net2, net3, net4])\n",
    "\n",
    "    net5 = deconv_block(net4, nf*4, (2,2), (2,2),   dropout=args.drop_p,regularizer=args.reg)\n",
    "    net5 = concatenate([net5, net1])\n",
    "    net6 = deconv_block(net5, nf*4, (3,3), (1,1), 'same',  dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    ## Position-wise Regression\n",
    "    net7 = concatenate([net6, start_input, net_temp], axis=-1)\n",
    "    net7 = gn_block(net7, nf*4, kernel_size=(1,1), dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    output = Conv2D(1, kernel_size=(1,1), padding='same', kernel_regularizer=regularizers.l2(args.reg))(net7)\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    model = Model(inputs=input_tensors, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce14749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(STAMP, LAG, STEP):\n",
    "\n",
    "    x_train, temporal_train, y_train = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=False)\n",
    "    x_valid, temporal_valid, y_valid = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=True)\n",
    "\n",
    "    input_shape = [10, 20, LAG]\n",
    "    model = TGNet(input_shape)\n",
    "\n",
    "    model.compile(loss=['mean_absolute_error'], \n",
    "               optimizer=Adam(lr=0.001, decay=args.decay), \n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "    \n",
    "    print('===== START TRAINGING =====')\n",
    "    \n",
    "#     with tf.device('/CPU:0'): # 텐서를 CPU에 할당\n",
    "    best_eval_loss = 100000\n",
    "    patience = 0\n",
    "\n",
    "    for idx in range(args.epoch): # epoch\n",
    "\n",
    "        print(f'Epoch = {idx}')\n",
    "        model.fit([x_train, temporal_train], y_train, \n",
    "                  batch_size=args.batch, epochs=1, shuffle=True,verbose=2)\n",
    "\n",
    "        eval_loss = model.evaluate([x_valid, temporal_valid], y_valid, \n",
    "                                   batch_size=args.batch, verbose=2)\n",
    "        patience += 1\n",
    "        if patience > args.patience:\n",
    "            break\n",
    "\n",
    "        if best_eval_loss > eval_loss[-1]:\n",
    "            if not os.path.exists('./model_saved'):\n",
    "                os.mkdir('./model_saved')\n",
    "            else:\n",
    "                model.save(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}_step{STEP}_v2.h5')\n",
    "\n",
    "            best_eval_loss = eval_loss[-1]\n",
    "            patience = 0\n",
    "    print('===== END TRAINGING =====')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0856a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_result(data):\n",
    "    num_row, h, w = data.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    return np.reshape(data, [num_row, num_col])\n",
    "\n",
    "def save_test_output(pred_inverse, y_inverse, output_path=None):\n",
    "    num_row, h, w = pred_inverse.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    assert pred_inverse.shape[:3] == y_inverse.shape[:3]\n",
    "    if output_path == None:\n",
    "        output_path = './model_output/temporal_directory'\n",
    "        print(\"[!] Please Assign Output Path in Arguments\")\n",
    "\n",
    "    np_pred = flatten_result(pred_inverse) #np.reshape(pred_inverse, [num_row, num_col])\n",
    "    np_y = flatten_result(y_inverse) #np.reshape(y_inverse, [num_row, num_col])\n",
    "\n",
    "    col_name = ['col_'+str(i) for i in range(0, num_col)]\n",
    "    index = np.arange(0, num_row)\n",
    "    df_pred = pd.DataFrame(np_pred, columns=col_name, index=index)\n",
    "    df_y = pd.DataFrame(np_y, columns=col_name, index=index)\n",
    "\n",
    "    df_y.to_csv(output_path+'_gt_v2.csv', index=False)\n",
    "    df_pred.to_csv(output_path+'_pred_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6b1b0",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b4665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_forecast(STAMP, LAG, STEP):\n",
    "    # Load saved model\n",
    "    model = tf.keras.models.load_model(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}_step{STEP}_v2.h5')\n",
    "    \n",
    "    min_x, max_x = get_min_max(load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz'), 'min_max')\n",
    "    x_test, temporal_test, y_test = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=False, valid=False)\n",
    "    \n",
    "    temporal_test_step1 = temporal_test[:,0,:]\n",
    "    y_pred =  model.predict([x_test, temporal_test_step1])\n",
    "    y_true = np.expand_dims(y_test[:,:,:,0], axis=-1)\n",
    "    y_pred_inv = scaler(y_pred, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "    y_true_inv = scaler(y_true, 'min_max', inv=True, min_value=min_x, max_value=max_x)    \n",
    "    save_test_output(y_pred_inv, y_true_inv, output_path=f'./output/predictions/stamp{STAMP}_lag{LAG}_step{STEP}_v2')\n",
    "    RMSE = rmse(y_true_inv, y_pred_inv)\n",
    "    print('#'*57)\n",
    "    print(f'###  RMSE of STAMP {STAMP} LAG {LAG} STEP {STEP} = {RMSE} ###')\n",
    "    print('#'*57)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e322a5",
   "metadata": {},
   "source": [
    "## multi-step forecast (Direct Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d69e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 21:07:50.742469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 21:07:51.888158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5\n",
      "2022-09-28 21:07:51.889233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9020 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5\n",
      "2022-09-28 21:07:51.894028: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 203.44M (213319680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Success to load  ./data/x_train_stamp1_lag6_step48_v2.npz\n",
      "[*] Success to load  ./data/x_train_stamp1_lag6_step48_v2.npz\n",
      "[*] Success to load  ./data/x_test_stamp1_lag6_step48_v2.npz\n",
      "[*] Success to load  ./data/y_test_stamp1_lag6_step48_v2.npz\n",
      "[*] Success to load  ./data/temporal_test_stamp1_lag6_step48_v2.npz\n",
      "--- test dataset ---\n",
      "x_test.shape = (1386, 10, 20, 6)\n",
      "y_test.shape = (1386, 10, 20, 1)\n",
      "temporal_test.shape = (1386, 1, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 21:07:53.457791: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2022-09-28 21:07:53.457842: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2022-09-28 21:07:53.457886: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:438 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_13/dense_13/MatMul' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3612/1581557041.py\", line 7, in <cell line: 7>\n      single_step_forecast(STAMP=stamp, LAG=lag, STEP=step)\n    File \"/tmp/ipykernel_3612/2177302709.py\", line 9, in single_step_forecast\n      y_pred =  model.predict([x_test, temporal_test_step1])\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_13/dense_13/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_13/dense_13/MatMul}}]] [Op:__inference_predict_function_2162]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m stamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m ; lag \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m ; step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m48\u001b[39m\u001b[38;5;241m/\u001b[39mstamp)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# for i in range(2,26,2):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     train(STAMP=stamp, LAG=i, STEP=step)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43msingle_step_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTAMP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36msingle_step_forecast\u001b[0;34m(STAMP, LAG, STEP)\u001b[0m\n\u001b[1;32m      6\u001b[0m x_test, temporal_test, y_test \u001b[38;5;241m=\u001b[39m LoadData(STAMP\u001b[38;5;241m=\u001b[39mSTAMP, LAG\u001b[38;5;241m=\u001b[39mLAG, STEP\u001b[38;5;241m=\u001b[39mSTEP, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, valid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m temporal_test_step1 \u001b[38;5;241m=\u001b[39m temporal_test[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m  \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_test_step1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(y_test[:,:,:,\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m y_pred_inv \u001b[38;5;241m=\u001b[39m scaler(y_pred, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_max\u001b[39m\u001b[38;5;124m'\u001b[39m, inv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_value\u001b[38;5;241m=\u001b[39mmin_x, max_value\u001b[38;5;241m=\u001b[39mmax_x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model_13/dense_13/MatMul' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3612/1581557041.py\", line 7, in <cell line: 7>\n      single_step_forecast(STAMP=stamp, LAG=lag, STEP=step)\n    File \"/tmp/ipykernel_3612/2177302709.py\", line 9, in single_step_forecast\n      y_pred =  model.predict([x_test, temporal_test_step1])\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/core/dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_13/dense_13/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_13/dense_13/MatMul}}]] [Op:__inference_predict_function_2162]"
     ]
    }
   ],
   "source": [
    "args.epoch=1000\n",
    "print(args.epoch)\n",
    "\n",
    "stamp = 1 ; lag = 6 ; step = int(48/stamp)\n",
    "# for i in range(2,26,2):\n",
    "#     train(STAMP=stamp, LAG=i, STEP=step)\n",
    "single_step_forecast(STAMP=stamp, LAG=lag, STEP=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f107100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# args.epoch=100\n",
    "# print(args.epoch)\n",
    "\n",
    "# #########\n",
    "# stamp = 1\n",
    "# #########\n",
    "\n",
    "# lag_total = int(48/stamp) ; step_total = lag_total\n",
    "\n",
    "\n",
    "# table = np.zeros(shape=(step_total, lag_total))\n",
    "# for lag in range(1,lag_total+1):\n",
    "#     for step in range(1,lag+1):\n",
    "#         print(f'lag={lag} / step={step}')\n",
    "#         train(STAMP=stamp, LAG=lag, STEP=step)\n",
    "#         table[step-1,lag-1] = single_step_forecast(STAMP=stamp, LAG=lag, STEP=step)\n",
    "    \n",
    "# col_name = ['lag_'+str(i) for i in range(0, 24)]\n",
    "# index = np.arange(0, 24)\n",
    "# rmse_table = pd.DataFrame(table, columns=col_name, index=index)\n",
    "# rmse_table.to_csv(f'rmse_table_stamp{stamp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fd754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
