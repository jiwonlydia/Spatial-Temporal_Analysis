{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "A94Q1z9d-z_V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl_pAOmV-z_b"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.load('./data/coord_train.npy')\n",
    "test_dataset = np.load('./data/coord_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVT-SrXetnvM",
    "outputId": "632f8490-c651-44c6-bfaf-9f6c360b279f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 10, 20)\n",
      "(8760, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence 데이터로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(data, lag=8, bias=0, step=1, temp=False):\n",
    "    \"\"\"This function makes samples of the time series data\n",
    "    args:\n",
    "    - data : (# of data, height, width)\n",
    "    - lag : the length of sampling\n",
    "    - step : (step)-ahead forecasting label\n",
    "    return: \n",
    "    - data_x (# of sample, height, width, lag)\n",
    "    - data_y (# of sample, height, width, 1)\n",
    "    \"\"\"\n",
    "    num_row = len(data)\n",
    "    data_x, data_y = [], []\n",
    "    for idx in range(num_row):\n",
    "        strat_idx = idx + bias\n",
    "        try:\n",
    "            y = np.array(data[strat_idx+lag+(step-1)])\n",
    "            data_y.append(y)\n",
    "            if not temp:\n",
    "                x = np.transpose(data[strat_idx:strat_idx+lag], [1,2,0])\n",
    "                data_x.append(x)\n",
    "        except:\n",
    "            if len(np.shape(data_y)) <4 and not temp:\n",
    "                data_y = np.expand_dims(data_y, axis=-1)\n",
    "            print(\"Sampler Return\", np.shape(data_x), np.shape(data_y))\n",
    "            break\n",
    "            \n",
    "    if not temp:\n",
    "        return np.array(data_x), np.array(data_y)\n",
    "    else:\n",
    "        return np.array(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Data\n",
    "- 24시간 후를 예측하는 hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 8\n",
    "END_LAG = 16\n",
    "STEP = 1 #6\n",
    "BIAS = END_LAG - LAG # 16-8=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Return (8752, 10, 20, 8) (8752, 10, 20, 1)\n",
      "Sampler Return (8751, 10, 20, 8) (8751, 10, 20, 1)\n",
      "Sampler Return (8750, 10, 20, 8) (8750, 10, 20, 1)\n",
      "Sampler Return (8713, 10, 20, 24) (8713, 10, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_1, y_train_1 = sampler(train_dataset, lag=LAG, bias=0, step=1)\n",
    "x_train_2, y_train_2 = sampler(train_dataset, lag=LAG, bias=0, step=2)\n",
    "x_train_3, y_train_3 = sampler(train_dataset, lag=LAG, bias=0, step=3)\n",
    "\n",
    "# 24시간 후를 예측하는 hourly data\n",
    "x_train_24, y_train_24 = sampler(train_dataset, lag=24, bias=0, step=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Return (8752, 10, 20, 8) (8752, 10, 20, 1)\n",
      "Sampler Return (8751, 10, 20, 8) (8751, 10, 20, 1)\n",
      "Sampler Return (8750, 10, 20, 8) (8750, 10, 20, 1)\n",
      "Sampler Return (8713, 10, 20, 24) (8713, 10, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_1, y_test_1 = sampler(test_dataset, lag=LAG, bias=0, step=1)\n",
    "x_test_2, y_test_2 = sampler(test_dataset, lag=LAG, bias=0, step=2)\n",
    "x_test_3, y_test_3 = sampler(test_dataset, lag=LAG, bias=0, step=3)\n",
    "\n",
    "x_test_24, y_test_24 = sampler(test_dataset, lag=24, bias=0, step=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Data\n",
    "- 1일 후를 예측하는 daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,    1.5, ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]],\n",
       "\n",
       "       [[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,    1.8, ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]],\n",
       "\n",
       "       [[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,    1.7, ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,   -6. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]],\n",
       "\n",
       "       [[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,   -5.9, ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]],\n",
       "\n",
       "       [[-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        ...,\n",
       "        [-100. , -100. ,   -6.3, ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ],\n",
       "        [-100. , -100. , -100. , ..., -100. , -100. , -100. ]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_24, y_train_24 = sampler(train_dataset, lag=24, bias=0, step=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./TGNet/data/x_train_1.npz', x_train_1)\n",
    "np.savez('./TGNet/data/y_train_1.npz', y_train_1)\n",
    "\n",
    "np.savez('./TGNet/data/x_train_2.npz', x_train_2)\n",
    "np.savez('./TGNet/data/y_train_2.npz', y_train_2)\n",
    "\n",
    "np.savez('./TGNet/data/x_train_3.npz', x_train_3)\n",
    "np.savez('./TGNet/data/y_train_3.npz', y_train_3)\n",
    "\n",
    "np.savez('./TGNet/data/x_train_24.npz', x_train_24)\n",
    "np.savez('./TGNet/data/y_train_24.npz', y_train_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./TGNet/data/x_test_1.npz', x_test_1)\n",
    "np.savez('./TGNet/data/y_test_1.npz', y_test_1)\n",
    "\n",
    "np.savez('./TGNet/data/x_test_2.npz', x_test_2)\n",
    "np.savez('./TGNet/data/y_test_2.npz', y_test_2)\n",
    "\n",
    "np.savez('./TGNet/data/x_test_3.npz', x_test_3)\n",
    "np.savez('./TGNet/data/y_test_3.npz', y_test_3)\n",
    "\n",
    "np.savez('./TGNet/data/x_test_24.npz', x_test_24)\n",
    "np.savez('./TGNet/data/y_test_24.npz', y_test_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8752, 10, 20, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "# x_train = np.load('./TGNet/data/x_train_1.npz')\n",
    "# x_train['arr_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtdscoE--z_e"
   },
   "source": [
    "## Make Temporal Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (8760, 10, 20) , Test shape:  (8760, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: \", np.shape(train_dataset), \", Test shape: \", np.shape(test_dataset))\n",
    "\n",
    "# Setting Some Parameters \n",
    "num_train, num_test = np.shape(train_dataset)[0], np.shape(train_dataset)[0]\n",
    "num_row = num_train + num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "gHBrk_oO-z_f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17520, 24)\n"
     ]
    }
   ],
   "source": [
    "### Initialize numpy array of temporal information (one-hot encoding)\n",
    "# datasets_min_30 = np.zeros([num_row, 48]) # 30분 단위 시간 => 1시간 단위로 바꾸기\n",
    "\n",
    "datasets_hour = np.zeros([num_row, 24]) # 1시간 단위의 시간 (0시~23시)\n",
    "print(datasets_hour.shape)\n",
    "\n",
    "# datasets_dow = np.zeros([num_row, 7]) # dayofweek: 불필요\n",
    "# datasets_holiday = np.zeros([num_row, 1]) # 공휴일 여부: 불필요\n",
    "# datasets_prev_holiday = np.zeros([num_row, 1]) # 공휴일 전날 여부: 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "nW5-wZpU-z_f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17520, 24)\n"
     ]
    }
   ],
   "source": [
    "# 1 hour index are calculated below\n",
    "for i in range(num_row):\n",
    "    idx_hour = int(int(i)%24)\n",
    "    datasets_hour[i,idx_hour] = 1\n",
    "print(datasets_hour.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "SIDEMt5N-z_i"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data, idx):\n",
    "    return data[:idx], data[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRhaLACu-z_i"
   },
   "source": [
    "## Split Train&Test Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "2DGTormw-z_i"
   },
   "outputs": [],
   "source": [
    "train_index = num_train\n",
    "hour_train, hour_test = train_test_split(dataset_hour, train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 24)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ryGMQTj-z_i"
   },
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "gshBfRxF-z_j"
   },
   "outputs": [],
   "source": [
    "LAG = 8\n",
    "END_LAG = 16\n",
    "STEP = 1 #6\n",
    "BIAS = END_LAG - LAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Return (0,) (8752, 24)\n",
      "Sampler Return (0,) (8752, 24)\n",
      "Sampler Return (0,) (8751, 24)\n",
      "Sampler Return (0,) (8751, 24)\n",
      "Sampler Return (0,) (8750, 24)\n",
      "Sampler Return (0,) (8750, 24)\n",
      "Sampler Return (0,) (8713, 24)\n",
      "Sampler Return (0,) (8713, 24)\n"
     ]
    }
   ],
   "source": [
    "hour_train_y_1 = sampler(hour_train, lag=8, step=1, temp=True)\n",
    "hour_test_y_1 = sampler(hour_test, lag=8, step=1, temp=True)\n",
    "\n",
    "hour_train_y_2 = sampler(hour_train, lag=8, step=2, temp=True)\n",
    "hour_test_y_2 = sampler(hour_test, lag=8, step=2, temp=True)\n",
    "\n",
    "hour_train_y_3 = sampler(hour_train, lag=8, step=3, temp=True)\n",
    "hour_test_y_3 = sampler(hour_test, lag=8, step=3, temp=True)\n",
    "\n",
    "hour_train_y_24 = sampler(hour_train, lag=24, step=24, temp=True)\n",
    "hour_test_y_24 = sampler(hour_test, lag=24, step=24, temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8752, 24) (8752, 24)\n",
      "(8751, 24) (8751, 24)\n",
      "(8750, 24) (8750, 24)\n",
      "(8713, 24) (8713, 24)\n"
     ]
    }
   ],
   "source": [
    "temporal_train_1 = hour_train_y_1\n",
    "temporal_test_1 = hour_test_y_1\n",
    "\n",
    "temporal_train_2 = hour_train_y_2\n",
    "temporal_test_2 = hour_test_y_2\n",
    "\n",
    "temporal_train_3 = hour_train_y_3\n",
    "temporal_test_3 = hour_test_y_3\n",
    "\n",
    "temporal_train_24 = hour_train_y_24\n",
    "temporal_test_24 = hour_test_y_24\n",
    "\n",
    "print(np.shape(temporal_train_1), np.shape(temporal_test_1))\n",
    "print(np.shape(temporal_train_2), np.shape(temporal_test_2))\n",
    "print(np.shape(temporal_train_3), np.shape(temporal_test_3))\n",
    "print(np.shape(temporal_train_24), np.shape(temporal_test_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./data/temporal_train_1.npz', temporal_train_1)\n",
    "np.savez('./data/temporal_test_1.npz', temporal_test_1)\n",
    "\n",
    "np.savez('./data/temporal_train_2.npz', temporal_train_2)\n",
    "np.savez('./data/temporal_test_2.npz', temporal_test_2)\n",
    "\n",
    "np.savez('./data/temporal_train_3.npz', temporal_train_3)\n",
    "np.savez('./data/temporal_test_3.npz', temporal_test_3)\n",
    "\n",
    "np.savez('./data/temporal_train_24.npz', temporal_train_24)\n",
    "np.savez('./data/temporal_test_24.npz', temporal_test_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhJO8PTZ-z_k"
   },
   "source": [
    "# Important Remark\n",
    "For fair comparision with STDN setting, we only use 477 number of test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YPO9Dda-z_k"
   },
   "outputs": [],
   "source": [
    "# %mkdir NYC_taxi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlOhFDKV-z_k"
   },
   "outputs": [],
   "source": [
    "# np.savez('./NYC_taxi_dataset/x_st_train.npz', start_train_x)\n",
    "# np.savez('./NYC_taxi_dataset/x_st_test.npz', start_test_x)\n",
    "# np.savez('./NYC_taxi_dataset/x_end_train.npz', end_train_x)\n",
    "# np.savez('./NYC_taxi_dataset/x_end_test.npz', end_test_x)\n",
    "# np.savez('./NYC_taxi_dataset/y_st_train.npz', start_train_y)\n",
    "# np.savez('./NYC_taxi_dataset/y_st_test.npz', start_test_y)\n",
    "# np.savez('./NYC_taxi_dataset/temporal_train.npz', temporal_train)\n",
    "# np.savez('./NYC_taxi_dataset/temporal_test.npz', temporal_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljrG2AEp-z_k"
   },
   "source": [
    "## Coordinate Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0URWDEvS-z_k"
   },
   "outputs": [],
   "source": [
    "train_num, h, w = np.shape(start_train_y)[:-1]\n",
    "test_num = np.shape(start_test_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-KtmKau-z_l",
    "outputId": "e17029c2-efeb-4d17-c2d4-1a8ef8f1cbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 10, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "coord_y = np.expand_dims(np.array([[y]*w for y in range(h)]), axis=-1)\n",
    "coord_x = np.expand_dims(np.array([[x]*h for x in range(w)]), axis=-1)\n",
    "coord_x = np.transpose(coord_x, [1,0,2])\n",
    "coord_xy = np.concatenate([coord_y, coord_x], axis=-1)\n",
    "coord_xy = np.repeat(np.expand_dims(coord_xy, axis=0), repeats=num_row, axis=0)\n",
    "print(np.shape(coord_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXlRWIBswiSF",
    "outputId": "92db999d-d3d5-490c-b778-79b1468c0e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1904"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bw37jgIQ-z_l",
    "outputId": "8a80f9f8-9ec5-4270-c922-3cbaca4462ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 10, 20, 2) (976, 10, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "coord_train, coord_test = coord_xy[:len(start_train_y)], coord_xy[len(start_train_y):]\n",
    "print(np.shape(coord_train), np.shape(coord_test))\n",
    "np.savez('./NYC_taxi_dataset/coord_train.npz', coord_train)\n",
    "np.savez('./NYC_taxi_dataset/coord_test.npz', coord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWdCvQjq-z_l",
    "outputId": "10daebeb-bb96-4c40-e059-e3b4e0858f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uURlUd_wWZAK",
    "outputId": "222252ab-ea85-42d0-db68-6c3f1ffadef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "960-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-efgQWySWePi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SRhaLACu-z_i",
    "2ryGMQTj-z_i"
   ],
   "name": "Sampler.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
